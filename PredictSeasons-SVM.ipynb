{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nomes para as colunas\n",
    "columns = [\"Estacao\",\"Data\",\"Hora\",\"Prec\",\"TempMax\",\"TempMin\",\"Insolacao\",\"EvapoPiche\",\"TempCompMedia\",\n",
    "           \"UmidRelatMedia\", \"VelocVento\", \"Missing\"]\n",
    "\n",
    "#Tipos de dados em cada coluna\n",
    "types = {\"Hora\":np.uint16,\"Prec\":np.float64,\"TempMax\":np.float64,\"TempMin\":np.float64,\"Insolacao\":np.float64,\n",
    "         \"EvapoPiche\":np.float64,\"TempCompMedia\":np.float64,\"UmidRelatMedia\":np.float64,\"VelocVento\":np.float64}\n",
    "\n",
    "#Leitura do arquivo csv\n",
    "dataSet = pd.read_csv(\"Dados_INMET/Diarios/INMET-Dados_Diarios_Natal_1968-2018.csv\",sep=';',skiprows=48, nrows = 27003,\n",
    "          usecols = columns[1:11], names=columns, dtype = types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando data em variável do tipo datetime\n",
    "dataSet[\"Data\"] = pd.to_datetime(dataSet[\"Data\"], format = \"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando dados\n",
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando o tipo dos dados\n",
    "dataSet.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando os dados em dois dataframes, um para as 00:00 h e outro para as 12:00 h\n",
    "dataSet00, dataSet12 = dataSet[dataSet[\"Hora\"] == 0], dataSet[dataSet[\"Hora\"] == 1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando dataframe para os dados disponibilizados às 00:00 h\n",
    "dataSet00.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando dataframe para os dados disponibilizados às 12:00 h\n",
    "dataSet12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando a data no índice de cada dataframe\n",
    "dataSet00 = dataSet00.set_index(\"Data\")\n",
    "dataSet12 = dataSet12.set_index(\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descartando a coluna \"Hora\"\n",
    "dataSet00, dataSet12 = dataSet00.drop(columns = \"Hora\"), dataSet12.drop(columns = \"Hora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Juntando os dados em um mesmo dataframe (no caso, o dataSet00)\n",
    "for i in dataSet00.index:\n",
    "    try:\n",
    "        dataSet00[\"Prec\"].loc[i] = dataSet12[\"Prec\"].loc[i]\n",
    "        dataSet00[\"TempMin\"].loc[i] = dataSet12[\"TempMin\"].loc[i]\n",
    "    except:\n",
    "        print(\"Data \" + str(i.day) + \"/\" + str(i.month) + \"/\" + str(i.year) + \" Não encontrada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atribuindo à variável dataSet o DataFrame atualizado\n",
    "dataSet = dataSet00\n",
    "#Verificando dimensões do DataFrame\n",
    "print(dataSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminando dias que estejam faltando variáveis\n",
    "dataSet = dataSet.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando dimensões do DataFrame após excluir linhas com problema\n",
    "print(dataSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando a coluna Data de volta em uma coluna de informações do dataSet\n",
    "dataSet = dataSet.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considerando os seguintes intervalos: \n",
    "- Outono: 20 de março a 21 de junho (fechado em 20/03 e aberto em 21/06)\n",
    "- Inverno: 21 de junho a 22 de setembro (fechado em 21/06 e aberto em 22/09)\n",
    "- Primavera: de 22 de setembro a 21 de dezembro (fechado em 22/09 e aberto em 21/12)\n",
    "- Verão: de 21 de dezembro a 20 de março (fechado em 21/12 e aberto em 20/03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Função que retorna a estação do ano para uma determinada data\n",
    "def season(data):\n",
    "    if (data.month > 3 and data.month < 6) or (data.month == 3 and data.day >= 20) or (data.month == 6 and data.day < 21):\n",
    "        return \"Out\"\n",
    "    if (data.month > 6 and data.month < 9) or (data.month == 6 and data.day >= 21) or (data.month == 9 and data.day < 22):\n",
    "        return \"Inv\"\n",
    "    if (data.month > 9 and data.month < 12) or (data.month == 9 and data.day >= 22) or (data.month == 12 and data.day < 21):\n",
    "        return \"Pri\"\n",
    "    else:\n",
    "        return \"Ver\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identificando a estação do ano na base de dados\n",
    "estacao = []\n",
    "for i in dataSet.index:\n",
    "    estacao.insert(i, season(dataSet.loc[i, \"Data\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contando quantos dados existem para cada estação\n",
    "print(\"Outono: \" + str(estacao.count(\"Out\")))\n",
    "print(\"Inverno: \" + str(estacao.count(\"Inv\")))\n",
    "print(\"Primavera: \" + str(estacao.count(\"Pri\")))\n",
    "print(\"Verão: \" + str(estacao.count(\"Ver\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adicionando a estação do ano na base de dados\n",
    "dataSet[\"Season\"] = estacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminando a coluna \"Data\" e visualizando dados\n",
    "dataSet = dataSet.drop(columns=\"Data\")\n",
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando a variável que será prevista (Y) em função das demais variáveis (X) e convertendo-os em um ndarray\n",
    "X = np.array(dataSet.drop(columns = \"Season\"))\n",
    "Y = np.array(dataSet[\"Season\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando conjunto de treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizando o conjunto de treino\n",
    "print(X_train)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Efetuando uma transformação robusta nos dados\n",
    "sc = RobustScaler(quantile_range = (5.0,95.0))\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = SVC(C = 10000000.0, kernel = 'rbf', random_state = 0, gamma = 0.0001)\n",
    "classifier.fit(X_train, Y_train)\n",
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matriz de confusao, cujos valores da diagonal principal sao os acertos, acima da diagonal principal falsos-positivos e abaixo, falso-negativos\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "print(cm)\n",
    "#Soma de todas as iteracoes feitas exibidas na matriz de confusao\n",
    "total_iteracoes = 0\n",
    "acerto_local = 0\n",
    "for l in range(len(cm)):\n",
    "    for c in range(len(cm[0])):\n",
    "        total_iteracoes = total_iteracoes + cm[l][c]\n",
    "        if l == c:\n",
    "            acerto_local = acerto_local + cm[l][l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(acerto_local / total_iteracoes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
