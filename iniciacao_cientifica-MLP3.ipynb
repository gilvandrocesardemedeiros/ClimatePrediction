{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importando bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nomes para as colunas\n",
    "columns = [\"Estacao\",\"Data\",\"Hora\",\"Prec\",\"TempMax\",\"TempMin\",\"Insolacao\",\"EvapoPiche\",\"TempCompMedia\",\n",
    "           \"UmidRelatMedia\", \"VelocVento\", \"Missing\"]\n",
    "\n",
    "#Tipos de dados em cada coluna\n",
    "types = {\"Hora\":np.uint16,\"Prec\":np.float64,\"TempMax\":np.float64,\"TempMin\":np.float64,\"Insolacao\":np.float64,\n",
    "         \"EvapoPiche\":np.float64,\"TempCompMedia\":np.float64,\"UmidRelatMedia\":np.float64,\"VelocVento\":np.float64}\n",
    "\n",
    "#Leitura do arquivo csv\n",
    "dataSet = pd.read_csv(\"Dados_INMET/Diarios/INMET-Dados_Diarios_Natal_1968-2018.csv\",sep=';',skiprows=48, nrows = 27003,\n",
    "          usecols = columns[1:11], names=columns, dtype = types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando data em variável do tipo datetime\n",
    "dataSet[\"Data\"] = pd.to_datetime(dataSet[\"Data\"], format = \"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando dados\n",
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando o tipo dos dados\n",
    "dataSet.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando os dados em dois dataframes, um para as 00:00 h e outro para as 12:00 h\n",
    "dataSet00, dataSet12 = dataSet[dataSet[\"Hora\"] == 0], dataSet[dataSet[\"Hora\"] == 1200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando dataframe para os dados disponibilizados às 00:00 h\n",
    "dataSet00.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando dataframe para os dados disponibilizados às 12:00 h\n",
    "dataSet12.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando a data no índice de cada dataframe\n",
    "dataSet00 = dataSet00.set_index(\"Data\")\n",
    "dataSet12 = dataSet12.set_index(\"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Descartando a coluna \"Hora\"\n",
    "dataSet00, dataSet12 = dataSet00.drop(columns = \"Hora\"), dataSet12.drop(columns = \"Hora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Juntando os dados em um mesmo dataframe (no caso, o dataSet00)\n",
    "for i in dataSet00.index:\n",
    "    try:\n",
    "        dataSet00[\"Prec\"].loc[i] = dataSet12[\"Prec\"].loc[i]\n",
    "        dataSet00[\"TempMin\"].loc[i] = dataSet12[\"TempMin\"].loc[i]\n",
    "    except:\n",
    "        print(\"Data \" + str(i.day) + \"/\" + str(i.month) + \"/\" + str(i.year) + \" Não encontrada!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Atribuindo à variável dataSet o DataFrame atualizado\n",
    "dataSet = dataSet00\n",
    "#Verificando dimensões do DataFrame\n",
    "print(dataSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eliminando dias que estejam faltando variáveis\n",
    "dataSet = dataSet.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando dimensões do DataFrame após excluir linhas com problema\n",
    "print(dataSet.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando a coluna Data de volta em uma coluna de informações do dataSet\n",
    "dataSet = dataSet.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando cada elemento da label Data em três novas labels: dia, mes e ano\n",
    "mes, ano,  = [], []\n",
    "for i in dataSet.index:\n",
    "    mes.insert(i, dataSet.loc[i, \"Data\"].month)\n",
    "    ano.insert(i, dataSet.loc[i, \"Data\"].year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformando cada elemento da label Data na quantidade de dias passados a contar da data 01/01/1968\n",
    "data_referencia = datetime.strptime('1968-01-01', '%Y-%m-%d')\n",
    "for i in dataSet.index:\n",
    "    dataSet.loc[i, \"Data\"] = (dataSet.loc[i, \"Data\"] - data_referencia).days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adicionando as labels para o DataFrame dataSet e eliminando a coluna \"Data\"\n",
    "dataSet[\"Mes\"], dataSet[\"Ano\"] = mes, ano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizando os dados\n",
    "dataSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando a variável que será prevista (Y) em função das demais variáveis (X) e convertendo-os em um ndarray\n",
    "X = np.array(dataSet.drop(columns = \"TempMax\"))\n",
    "Y = np.array(dataSet[\"TempMax\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separando conjunto de treino e teste\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizando o conjunto de treino\n",
    "print(X_train)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Efetuando uma transformação do tipo: z = (x - u) / s, normalizando em termos do desvio padrão\n",
    "sc = StandardScaler()\n",
    "X_train[:,:-2] = sc.fit_transform(X_train[:,:-2])\n",
    "X_test[:,:-2] = sc.transform(X_test[:,:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verificando os dados de treino após a transformação\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Criando um modelo de MLP\n",
    "mlp = Sequential()\n",
    "#Adicionando a camada de entrada\n",
    "mlp.add(Dense(activation = 'relu', input_dim = len(X_train[0]), units = 40, kernel_initializer = 'uniform'))\n",
    "#Adicionando a segunda camada\n",
    "mlp.add(Dense(activation = 'relu', units = 20, kernel_initializer = 'uniform'))\n",
    "#Adicionando a terceira camada\n",
    "mlp.add(Dense(activation = 'relu', units = 10, kernel_initializer = 'uniform'))\n",
    "#Adicionando a quarta camada\n",
    "mlp.add(Dense(activation = 'relu', units = 5, kernel_initializer = 'uniform'))\n",
    "#Adicionando a camada de saída\n",
    "mlp.add(Dense(units = 1, kernel_initializer='normal'))\n",
    "# Compilando o modelo\n",
    "mlp.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
    "#Mostrando um sumário do modelo de MLP criada\n",
    "mlp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Treinando a MLP rede, a partir do modelo de MLP criado\n",
    "rede = mlp.fit(X_train, Y_train, epochs=100, verbose=1, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mostrando o processo de treino graficamente\n",
    "plt.plot(rede.history['loss'])\n",
    "plt.plot(rede.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim(0,1)\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fazendo uma previsão com base nos dados de teste\n",
    "Y_previsto = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mostrando o array de dados previstos\n",
    "print(Y_previsto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mostrando o array de dados reais que deveriam ter sido previstos no passo anterior\n",
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculando e mostrando o erro mínimo quadrático entre o Y previsto e o Y real\n",
    "print(mean_squared_error(Y_previsto, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
